---
date: "`r Sys.Date()`"
author: "John/Jane Doe, Univ. Florida"
output:
  pdf_document:
    latex_engine: pdflatex
    keep_tex: yes
header-includes:
  - \usepackage{float}
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE) 
# Specify the name of the dataset here as data_set_name.
data_set_name <- "FDACS_UFGA8201_peanut.94.xlsx"
#data_set_name <- "FL_Crop_BMP_errors_for_testing_QA_QC.xlsx" # or whatever the path is.
data_set_name <- gsub("\\\\", "/", data_set_name)  # Escape backslashes early!

file_path <- file.path("Test_data", data_set_name)
#file_path <- file.path(data_set_name)

# Load libraries
library(knitr)  # Main library for producing PDF output via LaTex
library(kableExtra) # Provides added funtionality for kable()
library(xtable)
library(glue)
library(Hmisc)
library(ggplot2)
library(maps)
library(mapdata)
library(ggrepel)
library(openxlsx2)  #Required for manipulating rows and columns of Excel
library(reshape2)

# Load workbook and define data_start_position in setup
wb <- wb_load(file_path)
ls_sheets <- wb_get_sheet_names(wb)
data_start_position <- which(ls_sheets == "M1. Experiments")  # Find the position of 'M1__Experiments' ONCE
dictionary_length <- 3

# Function to escape problem variables for LaTex
escape_latex <- function(x) {
  gsub("([#$%&_{}~^\\\\])", "\\\\\\1", x)
}
```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

---
title: "`r paste0('**Quality Assurance & Testing for the Crop BMP Dataset: \\n', data_set_name, "**")`"
---

# 1. Introduction

In preparing datasets based on the BMP data template, researchers need to check that their data are entered correctly, that all expected data are included, that the dataset is formatted as intended, and that all variables are correctly defined, including units of measurement. This report contains output from the R script "FL_Crop_BMP_QA_QC_single_dataset.Rmd", which conducts a series of quality control (QC) tests on a dataset prior to submitting the data to a repository or funding agency. 
Users are strongly urged to run this tool throughout dataset preparation rather than a single run upon a presumed "final" dataset. It is far easier to correct errors as an experiment is executed than waiting until all data acquisition and analyses are completed. Because this report includes guidance on possible sources of errors and emphasizes quality testing as a continuous process, use of the tool combines elements of quality assurance and quality control, hence "QA/QC".
The R script reviews crop BMP datasets according to the "four C's", whereby a dataset is:

1.  _Correct_: The values are accurate within the expected range of measurement error. We emphasize that the main error-checking should be done as a part of the normal data management pipeline prior to loading into the BMP template.
2.  _Complete_: The dataset is complete enough to enable further analysis without researchers having to seek guidance on how the crop was grown, weather conditions, etc.
3.  _Coherent_: Identifiers (keys) used to link data across sheets are used consistently.
4.  _Compatible_: By linking the BMP terminology to the ICASA standards, we expect that datasets can be used with a wide range of tools including artificial intelligence, machine learning and either simulation or statistical models. Information on the ICASA standards is available at the [ICASA GitHub site]( https://github.com/DSSAT/ICASA-Dictionary).

This document (the exported PDF) is produced by running the knit command within RStudio. It alternates between text (such as this section) and blocks of output from R. Users who are familiar with R and R Markdown should feel free to modify the markdown file as needed.

Issues we have encountered in test datasets include:

- Incorrect formatting of dates.
- Use of variables that include non-standard characters (e.g. "?").
- Introduction of new variables in unexpected positions.

We try to resolve these issues as they appear. Unresolved issues and suggestions for improvements should be reported at the "Issues" section of the GitHub site: https://github.com/DSSAT/Florida_Crop_BMP_Datasets

\newpage

## 1.1. Checking that the file is read as expected

We first list all sheets in the file `r data_set_name`. The list includes sheets
that are defined but have no data. 

```{r list-sheets, echo=FALSE, comment=""}

#' Retrieve a list of the names of all sheets in the dataset.
options(width = 84)
print(unname(ls_sheets))
```

\newpage

```{r , include=FALSE}
#' This loop should create approximately 30 data frames.
for (i in 1:length(ls_sheets)) {
  sheet_name <- ls_sheets[[i]]
  cat(sheet_name)
  df_name <- gsub("\\.", "_", make.names(sheet_name))  # Replace all periods
  df_temp <- wb_to_df(wb, sheet = sheet_name, colNames = TRUE,
                       start_row = 4, na.strings = "",
                       skip_empty_rows = TRUE, skip_empty_cols = TRUE)

  assign(df_name, df_temp)
  
}
```

# 2.0. Correct and Complete?: Summarizing the Content of Individual Sheets

Summaries are generated for the contents of each sheet except for the first three sheets, which contain instructions, and the last three, which contain the dictionaries. If sufficient numeric data are present, box plots are created for any numeric variables, including management levels. 

Results for each sheet should be checked to make sure they match expectations for all variables. The QA/QC tool is *not* shoudl never serve as the primary means of detecting incorrect values. We assume the researchers have already conducted extensive data validation.

## 2.1. Summaries for each sheet (Tabular summaries first, then box plots of numeric variables).

If numeric data appear in tables of frequencies, this means the data for the variable has been interpreted as text (character sting). This can arise if there are any non-numeric values such as "." in the original data. Be sure to inspect cells in the column below any problem variables in case a character has inadvertently been entered below the intended data.

Depending on the amount of data in the sheets, the corresponding group of box plots may appear after the summary of the next sheet (i.e., the box plots will be slightly out of order). 

```{r check-content-of-sheets, echo=FALSE, results='asis', comment=NA, warning=FALSE, fig.height=1.0, fig.width=3.3, fig.pos = 'h'}
#```{r check-content-of-sheets, echo=FALSE, comment=NA, warning=FALSE, fig.height=1.5, fig.width=3.0}
# With asis:
options(digits = 4)

# fig.pos is used to place figures after the text
#```{r check-content-of-sheets, echo=FALSE, comment=NA, warning=FALSE, results='hold', fig.height=0.8, fig.width=3.6, fig.pos = 'h'} 
#```{r check-content-of-sheets, echo=FALSE, comment=NA, warning=FALSE,  results='hold' , fig.height = 4.4}
options(width = 92) # Allows longer lines to display without wrapping

# Prior to processing dataframes, we create functions to test for sufficient
# numeric data.
has_5_numeric_values <- function(column) {
  sum(!is.na(column) & is.numeric(column)) >= 5
}

#' Prior to beginning processing, we need to limit  E3__Plots to six variables
#' because users have the option of providing plot maps that may cause additional
#' variables to be created
E3__Plots <- E3__Plots[ , c(1:6)]

#' Create function for summarizing non-numeric data
# Function to create a combined frequency table for all non-numeric variables in a data frame
create_combined_frequency_table <- function(df) {
  # Check if the data frame is empty
  if (nrow(df) == 0 || ncol(df) == 0) {
    return(data.frame(Variable = character(0), Value = character(0), Frequency = integer(0)))
  }
  
  # Identify non-numeric columns
  non_numeric_vars <- sapply(df, is.factor) | sapply(df, is.character)
  
  # If no non-numeric columns, return an empty data frame
  if (!any(non_numeric_vars)) {
    return(data.frame(Variable = character(0), Value = character(0), Frequency = integer(0)))
  }
  
  # List to store frequency tables
  freq_tables <- list()
  
  # Loop through non-numeric variables
  for (var in names(df)[non_numeric_vars]) {
    # Create frequency table
    freq_table <- as.data.frame(table(df[[var]]))
    colnames(freq_table) <- c("Value", "Frequency")
    
    # Add variable name as the first column
    freq_table <- cbind(Variable = var, freq_table)
    
    # Append to the list
    freq_tables[[var]] <- freq_table
  }
  
  # Combine all frequency tables into a single data frame
  combined_freq_table <- do.call(rbind, freq_tables)
  # Truncate Variable and Value to avoid printing issues
  combined_freq_table$Variable <- substr(combined_freq_table$Variable, 1, 27)
  combined_freq_table$Value    <- substr(combined_freq_table$Value   , 1, 45)

  return(combined_freq_table)
}

# Create function to replace -99 with NA in numeric columns
replace_neg99_with_na <- function(df) {
  # Apply the replacement only to numeric columns
  df[] <- lapply(df, function(col) {
    if (is.numeric(col)) {
      is.na(col) <- col == -99
    }
    return(col)
  })
  return(df)
}

# ls_sheets is the list of dataframe names
for (i in data_start_position:(length(ls_sheets) - dictionary_length)) {
  sheet_name <- ls_sheets[[i]]
  name_of_df <- gsub("\\.", "_", make.names(sheet_name))  # Replace all periods
  # Generate the Markdown header
  name_of_df_escaped <- escape_latex(name_of_df)
  cat(knitr::asis_output(paste0("Start processing of:", name_of_df_escaped, "\n\n")))
  df_being_checked <- get(name_of_df)  # Convert temporary name as string to valid df name.

  # Apply function to summarize non-numeric data
  df_frequencies <- create_combined_frequency_table(df_being_checked)
  print(kable(head(df_frequencies), caption = name_of_df_escaped, escape = FALSE))

  cat("\n\n")
 
  # Start of processing for numeric data
  # set working df to empty
  melted_data <- data.frame()
  selected_columns <- list()
  # Loop through columns of df
  for (j in 1:ncol(df_being_checked)) {
    # Check condition for selecting the column
    # The first test requires a variance > 0 which indicate all values in the column differ.
    # The second test checks that the variance is not NA, which would mean all values are NA.
    if (var(df_being_checked[, j], na.rm = TRUE) > 0 
        && !is.na(var(df_being_checked[, j], na.rm = TRUE))) {
      # Store the selected column along with its name
      selected_columns[[colnames(df_being_checked)[j]]] <- df_being_checked[, j]
    }
  }
  # Convert the list to a dataframe
  numeric_columns <- as.data.frame(selected_columns)
  
  # Convert values of -99 to NA
  numeric_columns <- replace_neg99_with_na(numeric_columns)
  
  # Create boxplot for all sheets that have sufficient numeric data (nrow > 5).
  # Test for no numeric data and skip boxplot
  if (
         (length(names(numeric_columns))) > 0 
      && (nrow(numeric_columns) > 5)
  ) {
    
    # Print summary of numeric data. Replacing summary() with Hmisc::describe()
    cat("\\begin{verbatim}\n")
      print(Hmisc::describe(numeric_columns))
    cat("\\end{verbatim}\n")
    
    # Create a horizontal box plot with individual numerical axes
    # Melt the dataframe to long format using reshape2 package
    melted_data <- reshape2::melt(numeric_columns)
    
# Loop through unique variables and create boxplots
for (m in unique(melted_data$variable)) {
  subset_data <- melted_data[melted_data$variable == m, ]
  boxplot <- ggplot(subset_data, aes(x = variable, y = value)) +
    geom_boxplot() +
    stat_summary(fun = mean, geom = "point", shape = 20, size = 6, color = "red", fill = "red") +
    ggtitle(m) +                       # Title will now match variable name
    coord_flip() +
    theme(
      plot.title = element_text(size = 8), 
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),    # Suppress x-axis text
      axis.text.y = element_blank()      # Suppress y-axis text
    )
  print(boxplot)
  cat("\n")
  }
    
  } 
  
cat(knitr::asis_output(paste0("\n END Processing ", name_of_df_escaped, "\n\n")))
cat("\n") # Empty line for paragraph break in Markdown
  
}
```

\newpage

## 2.2. Correct Dates? Formats correct? Events sequenced as expected?

Dates of key management events such as plantings, irrigations and harvests are sometimes entered incorrectly. A common problem is inversion of days and months (is '3/5/2021' "March 5, 2021" or "3 may 2021"?). Dates also may be entered in non-standard formats such as text. We prefer that the internal data format be used and data be expressed in ISO format (e.g., 2023-03-13 or yyyy-mm-dd). The various workbook formats for expressing dates are still acceptable so long as the data are truly recorded as dates.

### 2.2.1 Checking that date variables are formatted as dates

We first test whether dates reported for management, measurements and weather are in an acceptable date format. Not all date variables may be tested.

```{r check-dates2-2-1, echo = FALSE, comment=""}
#' Create a function to check date formats
date_format_check <- function(df, date_var) {
  # Capture the name of the data frame object for clearer messages
  df_name <- deparse(substitute(df))
  
  # --- Input Validation ---
  # Check first whether df lacks data
  if (is.null(df) || (is.data.frame(df) && nrow(df) == 0)) {
    return(sprintf("No rows with data in '%s'. Skipping date test.", df_name))
  }
  if (!is.character(date_var) || length(date_var) != 1) {
    stop("Error: Input 'date_var' must be a single character string (the column name).")
  }
  
  # --- Check if Column Exists ---
  if (!date_var %in% names(df)) {
    stop(sprintf("Error: Column '%s' not found in data frame '%s'.", date_var, df_name))
  }
  
  # --- Extract the Column ---
  col_data <- df[[date_var]]
  
  # --- Check Format and Content ---
  
  # Case 1: The column IS a Date object
  if (inherits(col_data, "Date")) {
    # Sub-case: It's Date type, but ALL values are NA
    if (all(is.na(col_data))) {
      # Message 3: No valid date values found (all NA)
      # Note: This interpretation assumes message 3 applies when the column
      # is technically 'Date' class but effectively empty.
      return(sprintf("No valid date values found for '%s' in '%s'. (Column is Date class but all values are NA)", date_var, df_name))
    } else {
      # Message 1: Valid Date format with at least one non-NA value
      return(sprintf("The variable '%s' in '%s' is valid.", date_var, df_name))
    }
  } else {
    # Case 2: The column is NOT a Date object (it's character, numeric, factor, etc.)
    # Message 2: Needs correction (covers text and other incorrect types)
    col_class <- class(col_data)[1] # Get the primary class for info
    return(sprintf("The variable '%s' in '%s' is given as %s and cannot be processed as given. Please correct.",
                   date_var, df_name, col_class))
  }
}

#' Test various dates that may appear in a dataset
print(date_format_check(E5__Planting, "Planting date"))
print(date_format_check(E6__Irrigation, "Date of irrigation"))
print(date_format_check(E7__Fertilizer, "Date"))
print(date_format_check(E8__Organic_Amendments, "Date"))
print(date_format_check(E9__Tillage, "Date"))
print(date_format_check(E10__Chemical_Applications, "Date"))
print(date_format_check(E11__Harvest, "Harvest date"))
print(date_format_check(E12__Preplant_Soil, "Sampling date"))
print(date_format_check(O3__Crop_Growth, "Sampling date"))
print(date_format_check(O4__Crop_Health, "Sampling date"))
print(date_format_check(O5__Soil_Surface_Properties, "Sampling date"))
print(date_format_check(O6__Soil_Layer_Properties, "Sampling date"))
print(date_format_check(W2__Daily_Weather_Data, "Date"))

```

### 2.2.2 Checking dates for management events using a timeline
As a further check of key dates reported for crop management, we plot management events for each combination of Experiment, Site and Year along a timeline. 
To reduce the potential number of plots, data from different treatments and replicates are pooled together. This means some timelines may include multiple instances of plantings, fertilizer applications, harvests or other events.
We currently do not consider crop phenology such as flowering or maturity dates.

```{r check-dates2-2-2, echo = FALSE, comment="", fig.height = 7.5}

#' Create cropping calendar for the dataset.
#' Assemble dates in different dataframes
#' E5. Planting
#' E6. Irrigation
#' E7. Fertilizer
#' E8. Organic Amendments
#' E9. Tillage
#' E11. Harvest
#' To facilitate processing, we extract the date and assign an event code. 
#' Because some sheets have no data (nrows = 0), we have to consider two cases.
E5Planting <- E5__Planting[,c("Experiment ID", "Site", "Year", "Planting date")]
E5Planting$Event <- "P"   # Coded for planting
colnames(E5Planting) <- c("Experiment ID", "Site", "Year", "Date", "Event")
E5Planting$Date <- as.Date(E5Planting$Date) # Ensures numeric values of NA don't cause type mismatch

E6Irrigation <- E6__Irrigation[,c("Experiment ID", "Site", "Year", "Date of irrigation")]
if(nrow(E6Irrigation) > 0){E6Irrigation$Event <- "I"   # Coded for irrigation
} else {E6Irrigation$Event <- character(0)}
  colnames(E6Irrigation) <- c("Experiment ID", "Site", "Year", "Date", "Event")
E6Irrigation$Date <- as.Date(E6Irrigation$Date)
  
E7Fertilizer <- E7__Fertilizer[,c("Experiment ID", "Site", "Year", "Date")]
if(nrow(E7Fertilizer) > 0){E7Fertilizer$Event <- "F"   # Coded for fertilizer
} else {E7Fertilizer$Event <- character(0)}
colnames(E7Fertilizer) <- c("Experiment ID", "Site", "Year", "Date", "Event")
E7Fertilizer$Date <- as.Date(E7Fertilizer$Date)

E8OrganicAmend <- E8__Organic_Amendments[,c("Experiment ID", "Site", "Year", "Date")]
if(nrow(E8OrganicAmend) > 0){E8OrganicAmend$Event <- "O"   # Coded for Organic amendments
} else {E8OrganicAmend$Event <- character(0)}
colnames(E8OrganicAmend) <- c("Experiment ID", "Site", "Year", "Date", "Event")
E8OrganicAmend$Date <- as.Date(E8OrganicAmend$Date)

E9Tillage <- E9__Tillage[,c("Experiment ID", "Site", "Year", "Date")]
if(nrow(E9Tillage) > 0){E9Tillage$Event <- "T"   # Coded for Tillage
} else {E9Tillage$Event <- character(0)}
colnames(E9Tillage) <- c("Experiment ID", "Site", "Year", "Date", "Event")
E9Tillage$Date <- as.Date(E9Tillage$Date)

E11Harvest <- E11__Harvest[,c("Experiment ID", "Site", "Year", "Harvest date")]
if(nrow(E11Harvest) > 0){E11Harvest$Event <- "H"   # Coded for Harvest
  } else {E11Harvest$Event <- character(0)}
colnames(E11Harvest) <- c("Experiment ID", "Site", "Year", "Date", "Event")
E11Harvest$Date <- as.Date(E11Harvest$Date)

#' With the six temporary data frames in hand, we merge them to create the 
#' data frame df_dates, removing any data frame that lacks date information.

#'  List of data frames
df_list <- list(E5Planting, E6Irrigation, E7Fertilizer, E8OrganicAmend, 
                E9Tillage, E11Harvest)

# Remove empty data frames from the list
df_list <- df_list[sapply(df_list, function(x) nrow(x) > 0)]

# Concatenate data frames
if (length(df_list) > 0) {
  df_dates <- do.call(rbind, df_list)
} else {
  df_dates <- data.frame()  # Return an empty data frame if all are empty
}

#' The list of merged dates can be displayed.
df_dates <- unique(df_dates) 
#' Often data from replicates or treatments will identical values, so we use unique() 
#' to simplify the dataset.

planting_dates <- aggregate(Date ~ `Experiment ID` + Site + Year, data = subset(df_dates, Event == "P"), FUN = min)

# Calculate DAP relative to Planting event
# Merge planting_dates with df_dates
df_dates <- merge(df_dates, planting_dates, 
                     by = c("Experiment ID", "Site", "Year"), suffixes = c("", ".Planting"))

# Calculate DAP relative to Planting event
df_dates$DAP <- with(df_dates, Date - Date.Planting)

# Create a separate data frame for geom_text
df_dates$DAP <- as.numeric(df_dates$DAP)

# Define custom point shapes and colors
point_shapes <- c(T = 16, P = 19, F = 17, I = 1, C = 12, H = 15, O = 13)
point_names <- c(T = "Tillage", P = "Planting", F = "Fertilizer", I = "Irrigation", H = "Harvest", C= "Agrochemicals", O= "Manure")
point_colors <- c(T = "brown", P = "dark green", F = "dark gray", I = "blue", H = "#CC9933", C= "red", O= "dark orange")
label_y_position <- c(T = -.5, P = -1.0, F = 1.5, I = 2.0, C = 1.0, H = 1.5, O = 1.3)

# Reorder the levels of the y-axis factor in reverse order
df_dates$"Experiment ID" <- factor(df_dates$"Experiment ID", levels = rev(levels(as.factor(df_dates$"Experiment ID")))) 

# Plot parallel timelines with labels above or below events and without legend
ggplot(df_dates, aes(x = DAP, y = paste(`Experiment ID`, Site, Year), 
                        shape = Event, color = Event, label = Event)) +
  geom_point(size = 2) +
  geom_text(aes(y = ifelse(Event %in% c("P", "F", "I", "C", "T", "H", "O"), paste(`Experiment ID`, Site, Year), NA)), 
            position = position_dodge(width = 0.2), size = 3, 
            vjust = label_y_position[subset(df_dates, Event %in% c("P", "F", "I", "C", "T", "H", "O"))$Event], 
            show.legend = FALSE) +
  scale_x_continuous(expand = c(.2, 0), name = "Days after planting") +
  theme_linedraw() +
  theme(legend.position = "plot") +
  scale_shape_manual(values = point_shapes) +
  scale_color_manual(values = point_colors, labels = point_names) +
  theme(panel.grid.major.y = element_line(color = "brown", linewidth = 0.3),  # Change color and width of horizontal grid lines
        panel.grid.major.x = element_blank(),  # Suppress vertical grid lines
        panel.grid.minor.x = element_blank(),  # Suppress vertical grid lines
        panel.grid.minor.y = element_blank(),
        plot.caption = element_text(hjust = 0)) + # Left-align the caption
  labs(title = "Timelines for Experiments, Sites and Years", y = NULL, 
     caption = "Replicates or treatments having identical event dates are shown as a single line.")
```

\newpage

## 2.3. Correct geocoordinates? Are locations mapped as expected?

Experience shows that datasets often have errors in location data. This section checks that any reported geocoordinates are roughly correct by mapping. Geocoordinates may appear in four sheets:

-   M2. Sites
-   E2. Fields
-   S1. Soil Metadata
-   W1. Weather Station Metadata

To facilitate processing, we extract the geocoordinates and the location name, and add as 'Source' the name of the individual sheet containing the data.

```{r get-geocoords, echo = FALSE, comment=""}
# Get the map data for Florida
florida_map <- map_data("state", region = "florida")

M2Sites <- M2__Sites[ , c("Site", "Latitude", "Longitude")]
M2Sites$Source <- "M2. Sites"
M2Sites <- M2Sites[, c(4, 1:3)]
colnames(M2Sites) <- c("Source", "Location", "Lat", "Long")

E2Fields <- E2__Fields[ , c("Site", "Latitude", "Longitude")]
E2Fields$Source <- "E2. Fields"
E2Fields <- E2Fields[, c(4, 1:3)]
colnames(E2Fields) <- c("Source", "Location", "Lat", "Long")

S1Soils <- S1__Soil_Metadata[ , c("Soil ID", "Latitude", "Longitude")]
S1Soils$Source <- "S1. Soil Meta"
S1Soils <- S1Soils[, c(4, 1:3)]
colnames(S1Soils) <- c("Source", "Location", "Lat", "Long")

W1Weather <- W1__Weather_Station_Metadata[ , c("Weather station name", 
                                               "Latitude of station", 
                                               "Longitude of station")]
W1Weather$Source <- "W1. Weather"
W1Weather <- W1Weather[, c(4, 1:3)]
colnames(W1Weather) <- c("Source", "Location", "Lat", "Long")

#' With the four temporary data frames in hand, we merge them to create the 
#' data frame df_geo_data, removing any data frame that lacks geocoordinates.

#' List of data frames
df_list <- list(M2Sites, E2Fields, S1Soils, W1Weather)

# Remove empty data frames from the list
df_list <- df_list[sapply(df_list, function(x) nrow(x) > 0)]

# Concatenate data frames
if (length(df_list) > 0) {
  df_geo_data <- do.call(rbind, df_list)
} else {
  df_geo_data <- data.frame()  # Return an empty data frame if all are empty
}
```

---

### 2.3.1. List of all expected geocoordinates

```{r list-geocoords, echo = FALSE, comment=""}
#' The list of merged geocoordinates is displayed.
df_geo_data_map <- df_geo_data
df_geo_data$Source <- format(df_geo_data$Source, justify = "left")
df_geo_data$Location <- format(df_geo_data$Location, justify = "left")

kable(df_geo_data[ ,c(1:4)], "latex", row.names = FALSE)
```

---

### 2.3.2. Displaying the reference map of Florida with any reported locations

Here we use a map of Florida as the base. If latitude or longitude values are very far off (e.g., if the values are reversed or longitude is assigned a positive value for anywhere in the Americas), the map will display, but it may be distorted and not look like the expected base map of Florida.

```{r, map-geocoords, echo = FALSE, comment=""}

#' Using ggplot(), a base map of Florida is created, then overlain with the 
#' locations as points using different colors depending on the variable Source.
ggplot() +
  geom_polygon(data = florida_map, aes(x = long, y = lat, group = group), 
               fill = "lightblue", color = "black") +
  
  # Add the geocoordinates as points
  geom_point(data = df_geo_data_map, aes(x = Long, y = Lat, color = Source), 
             size = 2, position = position_jitter(width = 0.05, height = 0.05)) +
  scale_color_manual(values = 
                       c("M2. Sites" = "red", "E2. Fields" = "green", 
                         "S1. Soil Meta" = "brown", "W1. Weather" = "blue")) +
  # Customize the plot appearance
  labs(title = "Geocoordinates of Reported Sites for Research, Soils or Weather", x = "Longitude", y = "Latitude") +
  theme_bw()
```

The option position = position_jitter is used so that if there are a large number of points with nearly identical locations, these are spread out slightly.

\newpage

## 2.4. Completeness of sheets: Checking whether sheets present in the template are missing from the dataset

Users may add sheets as needed but are discouraged from deleting sheets.

```{r, sheets-present, echo = FALSE, comment=""}

template_sheets <- c("START HERE", "Terminology", "List of sheets and keys", "M1. Experiments", "M2. Sites", "M3. Experimental Design", "E1. Treatments", "E2. Fields", "E3. Plots", "E4. Crop Information", "E5. Planting", "E6. Irrigation", "E7. Fertilizer", "E8. Organic Amendments", "E9. Tillage", "E10. Chemical Applications", "E11. Harvest", "E12. Preplant Soil", "O1. Analysis Methods", "O2. Yield Summary", "O3. Crop Growth",  "O4. Crop Health",  "O5. Soil Surface Properties", "O6. Soil Layer Properties", "O7. Water", "S1. Soil Metadata",   "S2. Soil Layer Properties", "W1. Weather Station Metadata", "W2. Daily Weather Data", 
 "Z1. Dictionary Metadata", "Z2. Dictionary Observations", "Z3. Dictionary Soils Weather" )

compare_sheet_names <- function(ls_sheets, template_sheets) {
  # Convert both lists to character vectors
  all_sheets <- unlist(ls_sheets)
  template_sheets <- unlist(template_sheets)
  
  # Find mismatches
  missing_in_dataset <- setdiff(template_sheets, all_sheets)
  missing_in_template <- setdiff(all_sheets, template_sheets)
  
  if (length(missing_in_dataset) == 0 & length(missing_in_template) == 0) {
    cat("The sheet names match.\n")
  } else {
    if (length(missing_in_dataset) > 0) {
      cat("The following sheets are in the template workbook but not in the dataset:\n")
      print(missing_in_dataset)
    }
    if (length(missing_in_template) > 0) {
      cat("The following sheets are in the dataset but not in the template workbook:\n")
      print(missing_in_template)
    }
  }
}

# Compare the sheets that contain data

compare_sheet_names(ls_sheets, template_sheets)

```

## 2.5. Completeness of data in individual sheets

To assess completeness, we need to know how many variables actually have data values (e.g., are not empty cells). Below is a count of total values for variables used in each sheet. To avoid the output being split into two sections, variable names that are longer than 30 characters are truncated.

```{r complete-sheets, echo = FALSE, comment=""}

# Start check of variables contained in data sheets

# Create an empty list to store results
results <- list()

# Initialize variables to store totals
total_non_missing <- 0
total_missing <- 0


# Iterate over sheet names
for (i in data_start_position:(length(ls_sheets) - dictionary_length)) {
  sheet_name <- ls_sheets[[i]]
  df_name <- gsub("\\.", "_", make.names(sheet_name))  # Replace all periods
  
  # Calculate total number of non-NA values for each column
  non_na_counts <- colSums(!is.na(get(df_name)))
  
  # Calculate total number of missing values for each column
  missing_counts <- colSums(is.na(get(df_name)))
  
  # Calculate total non-missing and missing values for this sheet
  total_non_missing_sheet <- sum(non_na_counts)
  total_missing_sheet <- sum(missing_counts)
  
  # Update totals
  total_non_missing <- total_non_missing + total_non_missing_sheet
  total_missing <- total_missing + total_missing_sheet
  
  # Create a data frame to store the results for this sheet
  sheet_results <- data.frame(
    Sheet_name = sheet_name,
    Variable = names(non_na_counts),
    Non_NA = non_na_counts,
    Missing = missing_counts
  )
  
  # Append the sheet results to the list
  results[[i]] <- sheet_results
}

# Print totals
cat("Total Non-Missing Values across all sheets:", total_non_missing, "\\n")
cat("Total Missing Values across all sheets:", total_missing, "\\n")

# Combine all the sheet results data frames into a single data frame
tabulated_values <- do.call(rbind, results)

# Print or return the final result
tabulated_values <- data.frame(tabulated_values, row.names = NULL)
kable(tabulated_values, "latex", row.names = FALSE, longtable = TRUE)
```
\newpage

# 3.0. Coherent Identifiers?

Index variables ('keys' in database terminology) from pairs of data frames are compared to make sure that the index values are identical across the sheets. This is fundamental to allowing different types of data to be linked across sheets. For example the values of 'Field location' should be the same in the sheets 'E1. Treatments' and 'E2. Fields'.

The basic approach for testing:

1.  Create two temporary data frames.
2.  Merge the data frames based on identifiers given as a list in the argument 'TestVar'.
3.  Reduce the two data frames to just the columns corresponding to 'TestVar'.
4.  Extract the unique combinations of values for each data frame.
5.  Add flag variables, 'from_df1' and 'from_df2', to make it easier to detect problems.
6.  Merge the the two data frames to create 'dfMerged'.
7.  Compare the length of the two data frames. The lengths should be identical.
8.  Print the merged test dataset 'dfMerged' to allow inspection by the users.

If the two frames are of different lengths, then there is a problem. If the two data frames are of the same length, one should still review 'from_df1' and 'from_df2' to see whether there are mismatches, which would be indicated by 'NA' in one of the two columns.

Common sources of mismatches include:

-   Inconsistent use of spaces such as 'Blk 1' vs. 'Blk1' or other puncutation ('Blk_1').
-   Simple spelling errors ('Fred' vs. 'Frred')
-   Experiments, treatments or plots that were either never planted or not harvested.
-   Extra rows being read in a given sheet, leading to an empty cell being assigned a value of NA. This may arise if a stray character appears outside of the intended range of data.

In the third case, it is helpful to provide a comment or note in the appropriate sheets to explain why additional data are missing.

```{r, create-TestIdsEqual, echo = FALSE, comment=""}
# Function to test whether identifiers match in list 'test_vars'
test_ids_equal <- function(df_test1, df_test2, test_vars) {
  df1_name <- deparse(substitute(df_test1))
  df2_name <- deparse(substitute(df_test2))
  
  # Test whether either df is empty with nrow()
  if (nrow(df_test1) == 0 || nrow(df_test2) == 0) {
    cat(paste("Insufficient data to test merge of ", df1_name, " and ", df2_name), "\\n")
  } else {
    df1 <- df_test1[, test_vars]
    df2 <- df_test2[, test_vars]
    
    df1 <- unique(df1)
    df2 <- unique(df2)
    
    df1 <- as.data.frame(df1)
    df2 <- as.data.frame(df2)
    
    colnames(df1) <- test_vars
    colnames(df2) <- test_vars
    
    df1$From_df1 <- 1
    df2$From_df2 <- 1
    
    df_merged <- merge(df1, df2, all = TRUE)
    
  # With merged set of identifiers, we need to check if lengths are equal.
  if (nrow(df1) > nrow(df2)) {
      message <- paste(df1_name, " is longer than ", df2_name)
    } else if (nrow(df1) < nrow(df2)) {
      message <- paste(df2_name, " is longer than ", df1_name)
    } else {
      message <- paste("The sheets ", df1_name, " and ", df2_name, " have the same length")
    }
    
    print(message, row.names=FALSE, quote = FALSE)
    kable(df_merged, "latex", longtable = TRUE, row.names=FALSE)
  }
}
```

\newpage

## 3.1. Comparing identifiers used in M1. Experiments, E1. Treatments, E2. Fields and E3. Plots

```{r, compare-IDs-M1-vs-E1-E3, echo = FALSE, comment=""}

#' Using TestIdsEqual() to compare identifiers in the sheet E1. Treatments
#' with values used in other sheets such as E2. Fields.
test_ids_equal(M1__Experiments, E1__Treatments, "Experiment ID")
test_ids_equal(E1__Treatments, E2__Fields, "Experiment ID")
test_ids_equal(E1__Treatments, E2__Fields, c("Experiment ID", "Site"))
test_ids_equal(E1__Treatments, E2__Fields, c("Experiment ID", "Site", "Field location"))
test_ids_equal(E1__Treatments, E3__Plots, c("Experiment ID", "Site", "Field location"))
```

---

## 3.2. Comparing identifiers used in E2. Fields vs. E3. Plots

```{r, compare-IDs-E2-vs-E3, echo = FALSE, comment=""}

#' Using TestIdsEqual() to compare identifiers in the sheet E2. Treatments
#' with values used in other sheets such as E3. Plots.
test_ids_equal(E2__Fields, E3__Plots, "Field location")
test_ids_equal(E2__Fields, E3__Plots, c("Experiment ID","Field location"))
```

---

## 3.3. Comparing identifiers used for soil and weather data

Note that the same soil profile or weather data may be used for several experiments or nearby sites.

```{r, compare-IDs-soil-weather, echo = FALSE, comment=""}

# Using test_ids_equal() to compare identifiers in other sheets such as for soils 
# and weather. 
test_ids_equal(E2__Fields, S1__Soil_Metadata, "Soil ID")
test_ids_equal(S1__Soil_Metadata, S2__Soil_Layer_Properties, "Soil ID")
test_ids_equal(E2__Fields, W1__Weather_Station_Metadata, "Weather station ID")
test_ids_equal(W1__Weather_Station_Metadata, W2__Daily_Weather_Data, "Weather station ID")
```

---

## 3.4. Comparing identifiers in E1__Treatments and the various management sheets

Testing for matches is extended to sheets for irrigations, fertilizers, etc. Because not all sheets will have data, we first create a list of sheets with data (number of rows \> 0).

```{r, compare-IDs-E1-vs-management, echo = FALSE, comment=""}

df_list <- lapply(ls_sheets, function(x) gsub("\\.", "_", make.names(x)))  # Replace all periods
df_non_zero <- list()
j <- 1

# Filter the dataframes that meet the conditions
for (i in 8:(length(df_list) - 3)) {
  df <- df_list[[i]]
  if (nrow(get(df)) > 0) {
    df_non_zero[[j]] <- df
    j <- j + 1
  }
}
#' We loop through df_non_0 to check for matching of Experiment IDs with the 
#' corresponding levels in the Treatments data frame.
#' The last seven sheets are excluded because they don't use Experiment.ID.
for (i in 2:(length(df_non_zero) - 7)) {
  test_df <- df_non_zero[[i]]
  cat(paste("Comparing E1__Treatments to", test_df, "for Experiment ID", "\n"))
  test_df <- get(test_df, envir = parent.frame())
  test_ids_equal(E1__Treatments, test_df, "Experiment ID")
  cat("\n")
}
```

\newpage

# 4. Compatible?: Checking That Variables Are Properly Described And Linked

We check whether all variables given in the various sheets appear in one of the three dictionary sheets. The dictionaries include variable names and definitions from the ICASA standards, so correct matching is needed to allow a dataset to be read by tools that use the ICASA standards. 

A common source of mismatches is when a variable is added to crop or soil measurements but is not added in the dictionary sheets. When variables are present in both sources, possible causes of mismatches include:

- Differences in capitalization or punctuation
- Names with leading or trailing blank spaces

We also check whether all variables have definitions and are linked to ICASA short names.
The processing works from the list of data frames, ls_sheets, but excludes the first three sheets and the three dictionaries.

```{r check-variables-in-dictionary, echo = FALSE, results='asis', comment=NA}

df_list <- as.list(ls_sheets)
df_variables_used <- data.frame()

#' We iterate through the data frames, skipping first three "readme"-type sheets
#' and last three sheets, which are the dictionaries.
for (i in data_start_position:(length(df_list) - dictionary_length)) {
  sheet_name <- ls_sheets[[i]]
  # Extract the data frame
  df <- get(gsub("\\.", "_", make.names(sheet_name)))  # Replace all periods
  
  # Extract the column names
  variable_names <- names(df)
  
  # Check if there are any columns in the dataframe
  if (length(variable_names) > 0) {
    # Create a data frame with the dataframe name and variable names
    temp_result <- data.frame(sheet_name = rep(df_list[[i]], times = 1, each = length(variable_names)),
                              VariableName = rep(variable_names, times = 1, each = 1),
                              stringsAsFactors = FALSE)
    
    # Bind the current result to the overall result data frame
    df_variables_used <- rbind(df_variables_used, temp_result)
    }
  }
# Return the final result data frame.
# df_variables_used
# Replace ".." with period-white space (". ") for sheet names
df_variables_used$SheetName <- gsub("  ", ". ", df_variables_used$sheet_name) 
# Replace "." with white space (". ") for variable names
df_variables_used$VariableName <- gsub("\\.", " ", df_variables_used$VariableName) 
df_variables_used$InVUsed <- 1
  
#' We create a single dictionary data frame from the three dictionaries in the 
#' Excel file.
df_dictionaries <- rbind(Z1__Dictionary_Metadata, Z2__Dictionary_Observations)
df_dictionaries <- rbind(df_dictionaries, Z3__Dictionary_Soils_Weather)
df_dictionaries$InDict <- 1
df_dictionaries$var_defined <- ifelse(!is.na(df_dictionaries$Definition)
                                      & !is.na(df_dictionaries$Definition), 1, 0)
df_dictionaries$has_ICASA_short <- ifelse(!is.na(df_dictionaries$'ICASA short name')
                                          & !is.na(df_dictionaries$'ICASA short name'),
                                          1, 0)

# names(df_dictionaries)
```

## 4.1. Comparing the number of variables either used in the sheets or defined in the dictionaries

The initial check is whether the data sheets have roughly the same number of variables as the three dictionary sheets.

```{r, compare-variable-numbers, echo = FALSE, comment=""}

cat(paste("Total variables in the spreadsheet: ", nrow(df_variables_used)))
cat(paste("Total variables in the three dictionaries: ", nrow(df_dictionaries)))
```

---

## 4.2. Compare lists of variables used in data sheets vs. the dictionaries

The second, more extensive check uses variable-by-variable matching. Mismatched variables are listed below. The columns InVUsed ("Included in Variables Used") and InDict ("In the Dictionaries") have a value of 1 if the variable is present in the respective source, the data sheets or the dictionaries. A value of NA means there is a mismatch. 

The script displays only mismatches, 'VariableName' is truncated to 35 characters so that each comparison will appear on a single line.

```{r Check-variable-names, echo = FALSE, warning=FALSE, comment=""}

check_dictionary_main <- merge(df_variables_used, df_dictionaries, 
                          by = c("SheetName", "VariableName"), all = TRUE)
check_dictionary_main$InVUsed <- ifelse(check_dictionary_main$InVUsed ==1
                                        & !is.na(check_dictionary_main$InVUsed), 1, 0)
check_dictionary_main$InDict  <- ifelse(check_dictionary_main$InDict  ==1
                                        & !is.na(check_dictionary_main$InDict), 1, 0)

check_dictionary <- check_dictionary_main[, c(1, 2, 4, 11)]

check_dictionary <- data.frame(check_dictionary)
mis_match <- subset(check_dictionary, (is.na(check_dictionary$InVUsed == 1 
                                      & check_dictionary$InDict == 1) 
                                      | check_dictionary$InVUsed != check_dictionary$InDict))

if (nrow(mis_match) > 0) 
    {
    kable(mis_match, "latex", row.names = FALSE, longtable = TRUE)
} else {
      print("[All variables used are preseent in the Dictionary worksheets.]")
    }

cat("\n")
```

---

## 4.3. Checking whether all variables used in the data sheets are defined.

If present, the list below contains all variables that lack a definition. 
- If 'var_defined' = 0,  the variable is in the Dictionary but lacks a definition.
- If 'var_defined' = NA, the variable is not in the Dictionary_

```{r Check-var_defs, echo = FALSE, warning=FALSE, comment=""}

check_dictionary2 <- check_dictionary_main[, c(1, 2, 12)]
un_defined_vars <- subset(check_dictionary2, check_dictionary2$var_defined == 0 
                          | is.na(check_dictionary2$var_defined))

if (nrow(un_defined_vars) > 0) 
    {
    kable(un_defined_vars, "latex", row.names = FALSE, longtable = TRUE)
} else {
      print("[All variables used have associated definitions.]")
    }

cat("\n")
```

---

## 4.4. Checking whether all variables are linked to an ICASA short name.

If present, the list below contains all variables that are *not* associated with an ICASA short name. 
- If 'var_defined' = 0,  the variable is in the Dictionary but no ICASA name is given.
- If 'var_defined' = NA, the variable is not in the Dictionary_
Further information on ICASA variables may be found at the [GitHub site](https://github.com/DSSAT/ICASA-Dictionary).

```{r Check-var_ICASA, echo = FALSE, warning=FALSE, comment=""}

check_dictionary3 <- check_dictionary_main[, c(1, 2, 13)]

no_ICASA_short <- subset(check_dictionary3, check_dictionary3$has_ICASA_short == 0 
                          | is.na(check_dictionary3$has_ICASA_short == 1))

no_ICASA_short$VariableName <- format(no_ICASA_short$VariableName, justify = "left")

if (nrow(no_ICASA_short) > 0) 
    {
  kable(no_ICASA_short, "latex", row.names = FALSE, longtable = TRUE)
} else {
      print("[All variables used have associated ICASA short name.]")
    }

cat("\n")
```

---

## 4.5. Checking the Workbook for Formulas, Merged Cells or Commented Cells

One concern with use of spreadsheets is that , merged cells, comments attached to specific cells, or other features  might cause problems in subsequent use of the data. We test first for use of formulas and merged cells, then test for comments attached to specific cells.
The checking script only returns the cell address (e.g., 'B17') or range ('B5:C2'). To save space in the report, only first 20 cases are displayed.

### 4.5.1. Checking spreadsheet for formulae or merged cells

Use of formulas is dangerous in datasets that are redistributed because they may results in values being updated incorrectly.

When read by software expecting complete rows and columns, values of merged blocks of cells are typically assigned only to the upper left cell of a merged block, and other cells are assumed to have missing values. To avoid possible misinterpretation of data, all merged cells should be un-merged.

```{r check-formulae-merges, echo = FALSE, comment=""}
#' Checking for formulas and merged cells in spreadsheet

for (k in 4:length(ls_sheets)) {        # Loop from first sheet to end of list
  # Get sheet for checking
  sheet <- ls_sheets[[k]]  
  # Test for formulas in cells
  formulas <- wb$worksheets[[k]]$sheet_data$cc
  # print(formulas)
  formulas <- formulas[formulas$f != "" 
                       | formulas$f_t != "" | formulas$f_ref != "" 
                       | formulas$f_ca != "" | formulas$f_si != "", c("row_r", "c_r")]
  
  if (nrow(formulas) > 0) {
  #  cat("Report for sheet: ", sheet, "\n")
    if (nrow(formulas) > 20) {formulas <- formulas[1:20, ]}
    cat("> For ", sheet, " formulas found at:\n")
    print(formulas, row.names = FALSE)
    cat("(Only first 20 instances of cells with formulas are shown.)\n")
  } #else {
    #cat("> No formulas found.\n")
    #}
  # cat(typeof(formulas))
  
  # Test for merged cells based on xml properties in sheet
  merge_cells <- wb$worksheets[[k]]$mergeCells # Extracts information about merged cells within the "testing" worksheet.
  merge_cells <- gsub("<mergeCell ref=\"", "", merge_cells)
  merge_cells <- gsub("\"/>", ",", merge_cells)
  len_merge_cells <- length(merge_cells)
  if (len_merge_cells > 0 & (merge_cells[1] == "A1:F1," | merge_cells[1] == "A1:G1,")) {
    merge_cells <- merge_cells[-1] # Negative index removes first element
    len_merge_cells <- len_merge_cells - 1
  }
  if (len_merge_cells > 20) {
    merge_cells <- merge_cells[1:20]
  }
  if (len_merge_cells > 0) {
    cat("> For ", sheet, " merged cells found at:\n")
    print(merge_cells, row.names = FALSE)
    cat(paste("\n","(Only the first 20 cell ranges are displayed.)\n\n"))
  } #else {
  #   cat("> No merged cells found.\n\n")
  # }
}

```

---

### 4.5.2. Checking for cells with attached comment

If specific comments are attached to cells, the information may be lost in subsequent processing. The preferred way to record comments is in note or comment variables on the respective sheet.

```{r check-comments, echo = FALSE, comment=""}
#' Test for cells with comments based on xml properties in workbook.
#' This is more complicated than one might expect because comments are
#' stored directly with cell values.
#' cat("Processing comments here\\n\\n")
comment_index <- data.frame()

#' Loop over sheets to create a dataframe that links sheets to the index 
#' used to link comments to sheets.
for (k in 4:length(ls_sheets)) {        # Loop from 1 to length of list
  # Extract key to relate index in comments to worksheets
  len <- length(comment_index)
  comment_relation <- wb$worksheets[[k]]$relships$comments
  # print(typeof(comment_relation))
  comment_relation <- ifelse(length(comment_relation) == 0, 0, comment_relation) 
  comment_index <- rbind(comment_index, c(k, comment_relation))
}
names(comment_index) <- c("sheet_number", "comment_relation")

#' Loop over list of comments to create a dataframe that links cell addresses
#' to the comment index 

comment_cells <- data.frame()
comments <- wb$comments
if (length(comments) > 0) {
  for (i in 1:length(comments)) {
    for (j in 1:length(comments[[i]])) {
        # print(comments[[i]][[j]]$ref)
        comment_cells <- rbind(comment_cells, c(i, comments[[i]][[j]]$ref))
      }
    }

  names(comment_cells) <- c("comment_relation", "cell")
  comment_cells <- merge(comment_index, comment_cells)
}

#' Report on sheets containing comments.
for (k in 1:length(ls_sheets)) {        # Loop from 1 to length of list
  comments_in_sheet <- comment_cells[comment_cells$sheet_number == k, ]
  ifelse(nrow(comments_in_sheet) > 20, comments_in_sheet[20, ], comments_in_sheet)
  # print(nrow(comments_in_sheet))
  if (nrow(comments_in_sheet) > 0) {
    cat(paste0("'", ls_sheets[k], "' contains cells with comments.\n"))
    cat(paste("The cells with comments are:\n"))
    print(comments_in_sheet[, 3])
    cat("(Only the first 20 cells are displayed)\n\n")
  }
  # else {
  #   cat(paste0("'", ls_sheets[k], "' had no cells with comments.\n\n"))
  # }
}

```

If no sheets are listed above, then no comments attached to cells were found.

---

```{r, echo = FALSE, results = 'asis'}
# Generate header text based on data/variables
header_text <- paste0("# End of analysis for ", data_set_name)
cat(header_text)
```

Please post questions or feedback to https://github.com/DSSAT/Florida_Crop_BMP_Datasets/tree/main

Users who are familiar with R and Rmarkdown are encouraged to modify the script as needed.

---